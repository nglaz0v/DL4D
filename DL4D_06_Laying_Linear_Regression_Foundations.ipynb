{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seeing linear regression in action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from sklearn.datasets import load_boston\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "# boston = load_boston()\n",
    "# X, y = scale(boston.data), boston.target\n",
    "data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
    "raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
    "boston_data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
    "boston_target = raw_df.values[1::2, 2]\n",
    "boston_feature_names = ('CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV')\n",
    "X, y = scale(boston_data), boston_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 0.741\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "regression = LinearRegression()\n",
    "regression.fit(X, y)\n",
    "\n",
    "print('R2 %0.3f' % regression.score(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CRIM:-0.9', 'ZN:1.1', 'INDUS:0.1', 'CHAS:0.7', 'NOX:-2.1', 'RM:2.7', 'AGE:0.0', 'DIS:-3.1', 'RAD:2.7', 'TAX:-2.1', 'PTRATIO:-2.1', 'B:0.8', 'LSTAT:-3.7']\n"
     ]
    }
   ],
   "source": [
    "print([a + ':' + str(round(b, 1)) for a, b in \n",
    "       zip(boston_feature_names, regression.coef_)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mixing Variable Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling the responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "lbl = LabelEncoder()\n",
    "enc = OneHotEncoder()\n",
    "qualitative = ['red', 'red', 'green', 'blue', \n",
    "               'red', 'blue', 'blue', 'green']\n",
    "labels = lbl.fit_transform(qualitative).reshape(8,1)\n",
    "print(enc.fit_transform(labels).toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with complex relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.728\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection  import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "pf = PolynomialFeatures(degree=2)\n",
    "poly_X = pf.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(poly_X,\n",
    "                    y, test_size=0.33, random_state=42)\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "reg_regression = Ridge(alpha=0.1)  #, normalize=True)\n",
    "reg_regression.fit(X_train,y_train)\n",
    "print ('R2: %0.3f' % r2_score(y_test,reg_regression.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Switching to Probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specifying a binary response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False False  True  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([0, 0, 0, 0, 1, 1, 1, 1])\n",
    "b = np.array([1, 2, 3, 4, 5, 6, 7, 8]).reshape(8,1)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regression = LinearRegression()\n",
    "regression.fit(b,a)\n",
    "print (regression.predict(b)>0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming numeric estimates into probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In-sample accuracy: 0.979\n",
      "Out-of-sample accuracy: 0.958\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection  import train_test_split\n",
    "\n",
    "binary_y = np.array(y >= 40).astype(int)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "            binary_y, test_size=0.33, random_state=5)\n",
    "logistic = LogisticRegression()\n",
    "logistic.fit(X_train,y_train)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('In-sample accuracy: %0.3f' % \n",
    "      accuracy_score(y_train, logistic.predict(X_train)))\n",
    "print('Out-of-sample accuracy: %0.3f' % \n",
    "      accuracy_score(y_test, logistic.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CRIM :   0.086\n",
      "     ZN :   0.230\n",
      "  INDUS :   0.580\n",
      "   CHAS :  -0.029\n",
      "    NOX :  -0.304\n",
      "     RM :   1.769\n",
      "    AGE :  -0.127\n",
      "    DIS :  -0.539\n",
      "    RAD :   0.919\n",
      "    TAX :  -0.165\n",
      "PTRATIO :  -0.782\n",
      "      B :   0.077\n",
      "  LSTAT :  -1.628\n"
     ]
    }
   ],
   "source": [
    "for var,coef in zip(boston_feature_names,\n",
    "                    logistic.coef_[0]):\n",
    "        print (\"%7s : %7.3f\" %(var, coef)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "classes: [0 1]\n",
      "\n",
      "Probs:\n",
      " [[0.33234217 0.66765783]\n",
      " [0.97060356 0.02939644]\n",
      " [0.99594746 0.00405254]]\n"
     ]
    }
   ],
   "source": [
    "print('\\nclasses:',logistic.classes_)\n",
    "print('\\nProbs:\\n',logistic.predict_proba(X_test)[:3,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guessing the Right Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the outcome of incompatible features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random features: 1 -> R2: 0.740\n",
      "Random features: 2 -> R2: 0.740\n",
      "Random features: 4 -> R2: 0.741\n",
      "Random features: 8 -> R2: 0.747\n",
      "Random features: 16 -> R2: 0.756\n",
      "Random features: 32 -> R2: 0.777\n",
      "Random features: 64 -> R2: 0.798\n",
      "Random features: 128 -> R2: 0.840\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                y, test_size=0.33, random_state=42)\n",
    "check = [2**i for i in range(8)]\n",
    "for i in range(2**7+1):\n",
    "    X_train = np.column_stack((X_train,np.random.random(\n",
    "        X_train.shape[0])))\n",
    "    X_test = np.column_stack((X_test,np.random.random(\n",
    "        X_test.shape[0])))\n",
    "    regression.fit(X_train, y_train)\n",
    "    if i in check:\n",
    "        print (\"Random features: %i -> R2: %0.3f\" % \n",
    "               (i, r2_score(y_train,regression.predict(X_train))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 0.561\n"
     ]
    }
   ],
   "source": [
    "regression.fit(X_train, y_train)\n",
    "print ('R2 %0.3f' \n",
    "   % r2_score(y_test,regression.predict(X_test)))\n",
    "# Please notice that the R2 result may change from run to \n",
    "# run due to the random nature of the experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving overfitting using selection and regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.728\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pf = PolynomialFeatures(degree=2)\n",
    "poly_X = pf.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(poly_X,\n",
    "                    y, test_size=0.33, random_state=42)\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "reg_regression = Ridge(alpha=0.1)  #, normalize=True)\n",
    "reg_regression.fit(X_train,y_train)\n",
    "print ('R2: %0.3f' \n",
    "   % r2_score(y_test,reg_regression.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning One Example at a Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding how SDG is different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example      1 R2 -6.255 coef: 0.112 -0.071 0.148 -0.040 0.075 -0.021 0.146 -0.113 0.243 0.224 0.118 0.037 0.110\n",
      "Example      2 R2 -6.168 coef: 0.065 -0.139 0.087 -0.078 0.055 -0.114 0.254 -0.054 0.154 0.140 0.282 0.068 0.152\n",
      "Example      4 R2 -6.060 coef: -0.074 -0.195 0.319 -0.171 0.064 -0.206 0.527 0.048 -0.041 0.266 0.075 0.219 0.353\n",
      "Example      8 R2 -5.775 coef: -0.249 -0.504 0.605 -0.343 0.098 0.005 0.807 -0.304 -0.095 0.332 -0.067 0.399 0.024\n",
      "Example     16 R2 -5.144 coef: -0.441 -0.430 0.298 -0.571 -0.002 0.004 0.519 -0.423 -0.279 0.292 -0.544 0.665 -0.065\n",
      "Example     32 R2 -4.494 coef: -0.562 -0.308 0.441 1.224 0.051 0.315 0.387 -0.567 0.055 0.629 -0.367 0.726 -0.513\n",
      "Example     64 R2 -2.947 coef: -0.986 0.419 0.107 1.648 -0.409 1.686 -0.427 -0.201 -0.029 0.448 -1.245 1.166 -1.913\n",
      "Example    128 R2 -1.791 coef: -0.546 0.863 0.119 1.137 -0.584 1.823 -0.288 -0.179 -0.281 0.096 -1.982 1.165 -2.029\n",
      "Example    256 R2 -0.608 coef: -0.804 0.619 -0.176 1.368 -0.770 3.135 -0.304 -0.514 -0.318 -0.201 -2.325 1.238 -2.758\n",
      "Example    512 R2 0.289 coef: -0.665 0.455 0.167 1.302 -0.570 3.073 -0.065 -1.175 0.163 0.223 -2.238 1.074 -2.937\n",
      "Example   1024 R2 0.626 coef: -0.775 0.302 0.178 1.177 -0.757 3.379 -0.176 -1.477 0.308 0.216 -2.190 1.125 -3.283\n",
      "Example   2048 R2 0.698 coef: -0.803 0.316 0.161 1.012 -1.068 3.231 -0.303 -1.886 0.537 0.116 -2.028 1.119 -3.565\n",
      "Example   4096 R2 0.709 coef: -0.869 0.424 0.169 0.973 -1.362 2.988 -0.350 -2.365 0.809 -0.074 -1.931 1.101 -3.739\n",
      "Example   8192 R2 0.715 coef: -0.964 0.638 0.140 0.902 -1.648 2.953 -0.420 -2.688 1.120 -0.404 -1.976 1.084 -3.881\n",
      "Example  16384 R2 0.722 coef: -1.015 0.788 0.231 0.819 -1.800 2.713 -0.395 -2.891 1.480 -0.778 -1.991 1.069 -3.893\n",
      "Example  32768 R2 0.721 coef: -1.081 0.844 0.271 0.872 -1.894 2.779 -0.386 -2.977 1.779 -1.162 -2.003 1.096 -3.949\n",
      "Example  65536 R2 0.726 coef: -1.093 0.890 0.391 0.802 -1.882 2.697 -0.368 -2.981 1.982 -1.315 -2.020 1.077 -3.904\n",
      "Example 131072 R2 0.724 coef: -1.103 0.892 0.371 0.848 -1.899 2.758 -0.373 -3.003 2.027 -1.398 -2.009 1.090 -3.950\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                    y, test_size=0.33, random_state=42)\n",
    "SGD = SGDRegressor(penalty=None,\n",
    "                   learning_rate='invscaling', \n",
    "                   eta0=0.01, power_t=0.25,\n",
    "                   max_iter=5, tol=None)\n",
    "\n",
    "power = 17\n",
    "check = [2**i for i in range(power+1)]\n",
    "for i in range(400):\n",
    "    for j in range(X_train.shape[0]):\n",
    "        SGD.partial_fit(X_train[j,:].reshape(1,13), \n",
    "                        y_train[j].reshape(1,))\n",
    "        count = (j+1) + X_train.shape[0] * i\n",
    "        if count in check:\n",
    "            R2 = r2_score(y_test,SGD.predict(X_test))\n",
    "            print ('Example %6i R2 %0.3f coef: %s' % \n",
    "            (count, R2, ' '.join(map(lambda x:'%0.3f' %x, SGD.coef_))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
